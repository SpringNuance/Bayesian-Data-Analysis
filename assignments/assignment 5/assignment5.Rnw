\documentclass[a4paper,11pt]{article}

%\usepackage[pdftex]{graphicx}
%\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[T1,mtbold,lucidacal,mtplusscr,subscriptcorrection]{mathtime}
\usepackage{times}
\usepackage{amsmath}
\usepackage{url}
\usepackage{enumerate}
\usepackage{parskip}
\usepackage[colorlinks,urlcolor=black]{hyperref}
\usepackage{microtype}

\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% if not draft, the smaller printable area makes the paper more readable
\topmargin -4mm
\oddsidemargin 0mm
\textheight 225mm
\textwidth 150mm

%\parskip=\baselineskip

\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\Sd}{Sd}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Beta}{Beta}
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\betacdf}{betacdf}
\DeclareMathOperator{\Invchi2}{Inv-\chi^2}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\N}{N}
\DeclareMathOperator{\U}{U}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\trace}{trace}
\newcommand{\vc}[1] { \mathbf{#1} }
\newcommand{\vs}[1] { \boldsymbol{#1} }

\pagestyle{empty}

\begin{document}
%\SweaveOpts{concordance=TRUE}
%\SweaveOpts{concordance=TRUE}
\thispagestyle{empty}

\section*{Bayesian data analysis -- Assignment 5}

% \HRule

\input{general_info.tex}

% General Knitr options
% (this cannot be input since the file runs knitr before LaTeX)
<<echo=FALSE,eval=TRUE>>=
options(continue="  ", prompt="> ")
knitr::opts_chunk$set(size = "small")
@

\newpage

\subsubsection*{Information on this assignment}
This assignment is related to Chapters 10 and 11. The maximum amount of points from this assignment is 6.

\textbf{Reading instructions:} Chapter 10 and 11 in BDA3, see \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch10.pdf}{\textbf{the reading instructions for Chapter 10}} and \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch11.pdf}{\textbf{the reading instructions for Chapter 11}}.

\textbf{Grading instructions:} The grading will be done in peergrade. All grading questions and evaluations for assignment 5 can be found \href{https://avehtari.github.io/BDA_course_Aalto/assignments/assignment5_rubric.html}{\textbf{in the rubric}}.

\textbf{Reporting accuracy:} For posterior statistics of interest, only report digits for which the Monte Carlo standard error (MCSE) is zero. \emph{Example:} If you estimate $E(\mu)=1.234$ with MCSE($E(\mu)$) = 0.01, you should report $E(\mu)=1.2$. See lecture video 4.1, \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch10.pdf}{the chapter notes}, and \href{https://avehtari.github.io/casestudies/Digits/digits.html}{a case study} for more information.

To use markmyassignment for this assignment, run the following code in R:

<<echo=TRUE,eval=FALSE,size="small">>=
library(markmyassignment)
assignment_path <-
  paste("https://github.com/avehtari/BDA_course_Aalto/,
      blob/master/assignments/tests/assignment5.yml", sep="")
set_assignment(assignment_path)
# To check your code/functions, just run
mark_my_assignment()
@

\newpage

\subsection*{Generalized linear model: Bioassay with Metropolis (6 points)}

Metropolis algorithm: Replicate the computations for the bioassay
example of section 3.7 in BDA3 using the Metropolis algorithm. The Metropolis algorithm is described in BDA3 Chapter 11.2. More information on the bioassay data can be found in Section 3.7 in BDA3, and in \href{https://avehtari.github.io/BDA_course_Aalto/chapter_notes/BDA_notes_ch3.pdf}{\textbf{Chapter 3 notes}}.

\begin{enumerate}
\item Implement the Metropolis algorithm as an R function for the bioassay data. Use the Gaussian prior as in Assignment 4, that is 
\begin{align*}
    \begin{bmatrix}
    \alpha \\ \beta
    \end{bmatrix}
    \sim
    \text{N} \left(\vs \mu_0, \vc \Sigma_0 \right), \qquad
    \text{where} \quad
    \vs \mu_0 = \begin{bmatrix} 0 \\ 10 \end{bmatrix} \quad \text{and} \quad
    \vc \Sigma_0 = \begin{bmatrix} 2^2 & 12 \\ 12 & 10^2 \end{bmatrix}.
\end{align*}

\begin{itemize}
\item[a)] Start by implementing a function called \texttt{density\_ratio} to compute the density ratio function, $r$ in Eq. (11.1) in BDA3. Below is an example on how the function should work. You can test  the function using {\tt markmyassignment}.
<<echo=FALSE>>=
density_ratio <- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n) 1.305179
@

<<echo=TRUE, eval=FALSE>>=
library(aaltobda)
data("bioassay")
@

<<echo=TRUE>>=
density_ratio(alpha_propose = 1.89, alpha_previous = 0.374,
              beta_propose = 24.76, beta_previous = 20.04,
              x = bioassay$x, y = bioassay$y, n = bioassay$n)
@

<<echo=FALSE>>=
density_ratio <- function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n) 0.7661784
@

<<echo=TRUE>>=
density_ratio(alpha_propose = 0.374, alpha_previous = 1.89,
              beta_propose = 20.04, beta_previous = 24.76,
              x = bioassay$x, y = bioassay$y, n = bioassay$n)
@

\textbf{Hint!} Compute with log-densities. Reasons are explained on page 261 of BDA3 and  lecture video 4.1. Remember that $p_1/p_0=\exp(\log(p_1)-\log(p_0))$. For your convenience we have provided functions that will evaluate the log-likelihood for given $\alpha$ and $\beta$ (see {\tt bioassaylp()} in the {\tt aaltobda} package). Notice that you still need to add the prior yourself and remember the unnormalized log posterior is simply the sum of log-likelihood and log-prior. For evaluating the log of the Gaussian prior you can use the function {\tt dmvnorm} from package {\tt aaltobda}. 

\item[b)] Now implement a function called {\tt metropolis\_bioassay()} which implements the Metropolis algorithm  using the {\tt density\_ratio()}.

\textbf{Hint!} Use a simple (normal) proposal distribution. Example proposals are $\alpha^* \sim N(\alpha_{t-1}, \sigma = 1)$ and $\beta^* \sim N(\beta_{t-1}, \sigma = 5)$. There is no need to try to find optimal proposal but test some different values for the jump scale ($\sigma$). Remember to report the one you used. Efficient proposals are dicussed in BDA3 p. 295--297 (not part of the course). In real-life a pre-run could be made with an automatic adaptive control to adapt the proposal distribution.
\end{itemize}

\item Include in the report the following:
\begin{enumerate}
\item[a)] Describe in your own words in one paragraph the basic idea of the Metropolis algorithm (see BDA3 Section 11.2, and lecture video 5.1).
\item[b)] The proposal distribution (related to \emph{jumping rule}) you used. Describe briefly in words how you chose the final proposal distribution you used for the reported results.
\item[c)] The initial points of your Metropolis chains (or the explicit mechanism for generating them).
\item[d)] Report the chain length or the number of iterations for each chain. Run the simulations long enough for approximate convergence (see BDA Section 11.4, and lecture 5.2).
\item[e)] Report the warm-up length (see BDA Section 11.4, and lecture 5.2).
\item[f)] The number of Metropolis chains used. It is important that multiple Metropolis chains are run for evaluating convergence (see BDA Section 11.4, and lecture 5.2).
\item[g)] Plot all chains for $\alpha$ in a single line-plot. Overlapping the chains in this way helps in visually assessing whether chains have converged or not.
\item[h)] Do the same for $\beta$.
% \item[h)] Report $\widehat{R}$ for $\alpha$ and $\beta$ separately. In complex scenarios, visual assessment is not sufficient and $\widehat{R}$ is a more robust indicator of convergence of the Markov chains.
\end{enumerate}

\item In complex scenarios, visual assessment is not sufficient and $\widehat{R}$ is a more robust indicator of convergence of the Markov chains. Use $\widehat{R}$ for convergence analysis. You can either use Eq. (11.4) in BDA3 or the more recent version described in \href{https://projecteuclid.org/euclid.ba/1593828229}{\textbf{a recent article}}. You should specify which $\widehat{R}$ you used. In R the best choice is to use function {\tt rhat\_basic()} from the package {\tt posterior}. Remember to remove the warm-up samples before computing $\widehat{R}$. Report the $\widehat{R}$ values for $\alpha$ and $\beta$ separately. Report the values for the proposal distribution you finally used.
  \begin{enumerate}
  \item[a]) Describe briefly in your own words the basic idea of $\widehat{R}$ and how to to interpret the obtained $\widehat{R}$ values.
  \item[b]) Tell whether you obtained good $\widehat{R}$ with first
    try, or whether you needed to run more iterations or how did you
    modify the proposal distribution.
  \end{enumerate}

\item Plot the draws for $\alpha$ and $\beta$ (scatter plot) and include this plot in your report. You can compare the results to Figure~3.3b in BDA3 to verify that your code gives sensible results. Notice though that the results in Figure~3.3b are generated from posterior with a uniform prior, so even when if your algorithm works perfectly, the results will look slightly different (although fairly similar).
\end{enumerate}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
