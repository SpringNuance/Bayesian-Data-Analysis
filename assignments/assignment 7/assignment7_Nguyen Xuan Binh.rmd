---
title: "BDA - Assignment 7"
author: "Anonymous"
header-includes:
   - \usepackage{amssymb}
   - \usepackage{amsmath}
   - \usepackage{inputenc}
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
    toc_depth: '3'
urlcolor: blue
---

```{r, include=FALSE}
library(aaltobda)
library(ggplot2)
library(posterior)
theme_set(theme_minimal())
library(cmdstanr)
library(posterior)
library(bayesplot)

```


# Exercise 1. Linear model: drowning data with Stan 
The provided data drowning in the aaltobda package contains the number of people who died
from drowning each year in Finland 1980–2019. A statistician is going to fit a linear model with Gaussian residual model to these data using time as the predictor and number of drownings as the target variable (see the related linear model example for the Kilpisjärvi-temperature data in the example Stan codes). She has two objective questions:
i) What is the trend of the number of people drowning per year? (We would plot the histogram
of the slope of the linear model.)
ii) What is the prediction for the year 2020? (We would plot the histogram of the posterior
predictive distribution for the number of people drowning at $\tilde{x} = 2020$.)
To access the data, use:

```{r}
library(aaltobda)
data("drowning")
```

Corresponding Stan code is provided in Listing 1. However, it is not entirely correct for the problem. First, there are three mistakes. Second, there are no priors defined for the parameters. In Stan, this corresponds to using uniform priors.
Your tasks are the following:\

## a) 
Find the three mistakes in the code and fix them. Report the original mistakes and your fixes clearly in your report. Include the full corrected Stan code in your report.\
Hint: You may find some of the mistakes in the code using Stan syntax checker. If you
copy the Stan code to a file ending .stan and open it in RStudio (you can also choose from
RStudio menu File $\rightarrow$ New File $\rightarrow$ Stan file to create a new Stan file), the editor will show you
some syntax errors. More syntax errors might be detected by clicking ‘Check’ in the bar just
above the Stan file in the RStudio editor. Note that some of the errors in the presented Stan
code may not be syntax errors.\

The three mistakes in the original Stan code are: 
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of data points
  vector[N] x; // observation year
  vector[N] y; // observation number of drowned
  real xpred; // prediction year
}

parameters {
  real alpha;
  real beta;
  real<upper=0> sigma; // <- MISTAKE 1: Should have been real<lower=0> sigma
}

transformed parameters {
  vector[N] mu = alpha + beta*x;
}

model {
  y ~ normal(mu, sigma) // <- MISTAKE 2: No semicolon at the end
}

generated quantities {
  real ypred = normal_rng(mu, sigma); // <- MISTAKE 3: should have been 
  // ypred = normal_rng(mu_pred, sigma), where mu_pred = alpha + beta * xpred. 
  // The derivation of mu_pred can be added to the transformed parameters.  
}

"
```

The completely fixed Stan code now becomes:
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of data points
  vector[N] x; // observation year
  vector[N] y; // observation number of drowned
  real xpred; // prediction year
}

parameters {
  real alpha;
  real beta;
  real<lower=0> sigma; // <- MISTAKE 1 fixed
}

transformed parameters {
  vector[N] mu = alpha + beta*x;
  real mu_pred = alpha + beta * xpred; // <- The derivation of mu_pred is added.  
}

model {
  y ~ normal(mu, sigma); // <- MISTAKE 2 fixed
}

generated quantities {
  real ypred = normal_rng(mu_pred, sigma); // <- MISTAKE 3 fixed
}

"
```

## b) 
Determine a suitable weakly-informative prior $normal(0; \sigma_\beta)$ for the slope beta. It is very unlikely that the mean number of drownings changes more than 50% in one year. The
approximate historical mean yearly number of drownings is 138. Hence, set $\sigma_\beta$ so that the following holds for the prior probability for $\beta: Pr(-69 < \beta < 69) = 0.99$.
Determine suitable value for $\sigma_\beta$ and report the approximate numerical value for it.

The distribution for $\sigma_\beta$ is a normal distribution with $\mu_\beta = 0$ and the standard deviation $\sigma_\beta$ is unknown. Because it is required that $Pr(-69 < \beta < 69) = 0.99$, it means $\beta = -69$ is the 0.5% quantile and $\beta = 69$ is the 99.5% quantile. Therefore, we need to calculate $\sigma_\beta$ such that the cumulative distribution $CDF[0, \sigma_\beta](-69) = 0.005$ and $CDF[0, \sigma_\beta](69) = 99.95$. Since the normal distribution is symmetric around the mean, we only need to find a solution that satisfies one equation, for example $CDF[0, \sigma_\beta](-69) = 0.005$.

To find the standard deviation of a normal distribution with a mean of 0 such that the cumulative distribution function (CDF) of the normal distribution is equal to the 0.005 quantile at x = -69, we can use the qnorm() function to estimate the standard deviation $\sigma_\beta$ by minimizing the error between the expected value -69 and the value returned by qnorm().

```{r}
find_sigma_beta <- function(sigmaSeq) {
  beta_quantile_value = -69 
  beta_quantile = 0.005
  minError = 1e9
  
  for (sigma in sigmaSeq){
    newError = abs(qnorm(p = beta_quantile, mean = 0, sd = sigma) - (beta_quantile_value))
    if (newError < minError){
      sigmaMin = sigma
      minError = newError
    }   
  }
  sigmaMin

}

sigma <- find_sigma_beta(seq(0,100, length.out = 100000))
print("The optimal beta sigma is: ")
print(sigma)
```
Therefore, the weakly informative prior for $beta$ is $P(\beta) \sim Normal(0, 26.787)$ (answer)

## c) 
Using the obtained $\sigma_\beta$, add the desired prior in the Stan code. In the report, in a separate section, indicate clearly how you carried out your prior implementation, e.g. “Added line ... in block ... ”\
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of data points
  vector[N] x; // observation year
  vector[N] y; // observation number of drowned
  real xpred; // prediction year
}

parameters {
  real alpha;
  real beta;
  real<lower=0> sigma; // <- MISTAKE 1 fixed
}

transformed parameters {
  vector[N] mu = alpha + beta*x;
  real mu_pred = alpha + beta * xpred; 
}

model {
  beta ~ normal(0, 26.787); // Added this line in the block model code
  y ~ normal(mu, sigma); 
}

generated quantities {
  real ypred = normal_rng(mu_pred, sigma);
}

"
```

Add the line "beta ~ normal(0, 26.787);" to the block model code\

## d) 
In a similar way, add a weakly informative prior for the intercept alpha and explain how you chose the prior.

Hint! Example resulting plots for the problem, with the fixes and the desired prior applied, are shown in Figure 1. If you want, you can use these plots as a reference for testing if your modified Stan code produces similar results. However, running the inference and comparing the plots is not required.

Because if we take into account very further time (a very long time ago), there are not any people at all, so there shouldn't be any drownings. This means that the intercept is expected to be 0. Finally, we have the equation for the mean number of drownings per year: $\alpha + \beta x = 138$. Since $\mu_b = 0$, it means that $\alpha$ should be accountable for the variance. So we set $\sigma_\alpha = 138$. The conclusion is $\alpha \sim N(0, 138)$
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of data points
  vector[N] x; // observation year
  vector[N] y; // observation number of drowned
  real xpred; // prediction year
}

parameters {
  real alpha;
  real beta;
  real<lower=0> sigma; // <- MISTAKE 1 fixed
}

transformed parameters {
  vector[N] mu = alpha + beta*x;
  real mu_pred = alpha + beta * xpred; 
}

model {
  alpha ~ normal(0, 138);
  beta ~ normal(0, 26.787);
  y ~ normal(mu, sigma); 
}

generated quantities {
  real ypred = normal_rng(mu_pred, sigma);
}

"
```

Add the line "alpha ~ normal(0, 138);" to the block model code\


Now, we load the model\
```{r}
set_cmdstan_path("C:/Users/nguye/Documents/.cmdstan/cmdstan-2.31.0")
file <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex1_model_correct.stan")
model <- cmdstan_model(file)
model$compile(quiet = FALSE)
```

```{r}
# Run MCMC using the 'sample' method
N = length(drowning$year) # The number of years
x = drowning$year  # The years (x-axis)
y = drowning$y # The number of drownings (y-axis)
xpred = 2020
drowning_data <- list(N=N, x=x, y=y, xpred=xpred)

iter_warmup <- 2000 # Number of warm up iterations
iter_sampling <- 2000 # Number of sampling iterations
chains <- 2 # Number of MCMC 

fit_mcmc <- model$sample(
  data = drowning_data,
  seed = 123,
  iter_warmup = iter_warmup,
  iter_sampling = iter_sampling,
  save_warmup = TRUE, # The warmup iterations is saved for visualization below
  chains = chains,
  parallel_chains = chains
)
```

```{r}
fit_mcmc$summary()
```

# Exercise 2. Hierarchical model: factory data with Stan 

Note! Both Assignment 8 and 9 build upon this part of the assignment, so it is important to get this assignment correct before you start with Assignment 8 and 9. If you need help, ask TAs.\

The factory data in the aaltobda package contains quality control measurements from 6
machines in a factory (units of the measurements are irrelevant here). In the data file, each column contains the measurements for a single machine. Quality control measurements are expensive and time-consuming, so only 5 measurements were done for each machine. In addition to the existing machines, we are interested in the quality of another machine (the seventh machine). To read in the data, just use:\

```{r}
library(aaltobda)
data("factory")
```

For this problem, you’ll use the following Gaussian models:\
- a separate model, in which each machine has its own model\
- a pooled model, in which all measurements are combined and there is no distinction between
machines\
- a hierarchical model, which has a hierarchical structure as described in BDA3 Section 11.6
As in the model described in the book, use the same measurement standard deviation $\sigma$ for all the groups in the hierarchical model. In the separate model, however, use separate measurement
standard deviation $\sigma_j$ for each group $j$. You should use weakly informative priors for all your
models.

The provided Stan code in Listing 2 given on the next page is an example of the separate model
(but with very strange results, why?). This separate model can be summarized mathematically as:\

$y_{ij} \sim N(\mu_j, \sigma_j)$ \
$\mu_j \sim N(0,1)$ \
$\sigma_j \sim Inv-{\chi^2} (10)$\

To run Stan for that model, simply use:\

```{r}
library(cmdstanr)
data("factory")
#sm <- cmdstan_model(stan_file = "[path to stan model code]")
#stan_data <- list(
#  y = factory,
#  N = nrow(factory),
#  J = ncol(factory)
#)
#model <- sm$sample(data = stan_data, refresh=1000)
#model
```

Note! These are not the results you would expect to turn in your report. You will need to change
the code for the separate model as well.
For each of the three models (separate, pooled, hierarchical), your tasks are the following:\

## a) 

Describe the model with mathematical notation (as is done for the separate model above).
Also describe in words the difference between the three models.\

Let $y_{ij}$ be the measure $i$ of the machine number $j$, which is between 1 and 6 in the table.\
Let $\mu_j$ be the measurement mean of machine number $j$.\
Let $\sigma_j$ be the measurement variance of machine number $j$.\

### Separate model

In the separate model, the measurements of each machine come from their respective Gaussian distributions. These distributions are independent of each other between the machines. The separate model assumes that all machines are different, thus they have their own mean $\mu_j$ and variance $\sigma_j$ distribution. Therefore, we cannot infer about any new machine in the separate model

Mathematical notation:\
$y_{ij} \sim N(\mu_j, \sigma_j)$\
$\mu_j \sim N(0,50)$\
$\sigma_j \sim N(0,20)$\

### Pooled model
In the pooled model, the measurements of all machines are thought to come from a single Gaussian distribution, which is shared among all machines. The pooled model assumes that all machines are similar and all of the measurements share the same constant mean $\mu_j$ and variance $\sigma_j$ prior. Therefore, we can not infer data for any new machine from this prior.

Mathematical notation:\
$y_{i} \sim N(\mu, \sigma)$\
$\mu \sim N(0,50)$\
$\sigma \sim N(0,20)$\

### Hierarchical model

Regarding the hyperparameters, the measurements share a common variance distribution, but hierarchical prior for the mean, where the means of each machine is inherited from the hyperparameter $\tau$. The hierachical model assumes that while the variance of the machines can be explained by coming from the same distribution, it makes the measurement mean more abstract by allowing all of the mean priors to be sampled from a distribution with tunable hyperparameters. This helps achieve the independent aspect of the measurements in the separate model while preserving the common grounds between the machines.\

Mathematical notation:\
$y_{ij} \sim N(\mu_j, \sigma_j)$\
$\sigma_j \sim N(0,20)$\
$\mu_{j} \sim N(\mu_\tau, \sigma_\tau)$\
$\mu_\tau \sim N(0,10)$\
$\sigma_\tau \sim N(0,10)$\

## b) 
Implement the model in Stan and include the code in the report. Use weakly informative
priors for all your models.

### Separate model

The chosen weakly informative priors for the separate model is:\
$\mu_j \sim N(0,50)$\
$\sigma_j \sim N(0,20)$\

```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  vector[K] mu;
  vector<lower=0>[K] sigma;
}

model {
  for (k in 1:K) {
    mu[k] ~ normal(0, 50);
    sigma[k] ~ normal(0, 20);
  }
  for (k in 1:K) {
    y[, k] ~ normal(mu[k], sigma[k]);
  }
}

generated quantities {
  array[K] real ypred;
  for (k in 1:K) {
    ypred[k] = normal_rng(mu[k], sigma[k]);
  }
}

"
```

Compiling the separate model\
```{r}
set_cmdstan_path("C:/Users/nguye/Documents/.cmdstan/cmdstan-2.31.0")
file_separate <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_separate.stan")
model_separate <- cmdstan_model(file_separate)
model_separate$compile(quiet = FALSE)
```
### Pooled model
The chosen weakly informative priors for the separate model is:\
$\mu \sim N(0,50)$\
$\sigma \sim N(0,20)$\
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  real mu; // There is only a single mu for all machines
  real<lower=0> sigma; // There is only a single sigma for all machines
}

model {
  // priors
  mu ~ normal(0, 50);
  sigma ~ normal(0, 20);

  // likelihood
  for (k in 1:K){
    y[,k] ~ normal(mu, sigma);
  }
}

generated quantities {
  real ypred = normal_rng(mu, sigma);
}

"
```

Compiling the pooled model\
```{r}
set_cmdstan_path("C:/Users/nguye/Documents/.cmdstan/cmdstan-2.31.0")
file_pooled <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_pooled.stan")
model_pooled <- cmdstan_model(file_pooled)
model_pooled$compile(quiet = FALSE)
```

### Hierarchical model
The chosen weakly informative priors for the separate model is:\
$\sigma \sim N(0,20)$\
$\mu_\tau \sim N(0,10)$\
$\sigma_\tau \sim N(0,10)$\
```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  vector[K] mu;
  real sigma;
  real mu_tau;
  real sigma_tau;
  real mu_ypred7;
}

model {
  mu_tau ~ normal(0, 10);
  sigma_tau ~ normal(0, 10);
  sigma ~ normal(0, 20);
  mu_ypred7 ~ normal(mu_tau, sigma_tau);
  for (k in 1:K) {
    mu[k] ~ normal(mu_tau, sigma_tau);
  }
  for (k in 1:K) {
    y[, k] ~ normal(mu[k], sigma);
  }
}

generated quantities {
  array[K] real ypred;
  for (k in 1:K) {
    ypred[k] = normal_rng(mu[k] , sigma);
  }
  real ypred7 = normal_rng(mu_ypred7, sigma);
}

"
```

Compiling the hierarchical model\
```{r}
set_cmdstan_path("C:/Users/nguye/Documents/.cmdstan/cmdstan-2.31.0")
file_hierarchical <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_hierarchical.stan")
model_hierarchical <- cmdstan_model(file_hierarchical)
model_hierarchical$compile(quiet = FALSE)
```

## c) 
Using the model (with weakly informative priors) report, comment on and, if applicable, plot
histograms for the following distributions:\
i) the posterior distribution of the mean of the quality measurements of the sixth machine.\
ii) the predictive distribution for another quality measurement of the sixth machine.\
iii) the posterior distribution of the mean of the quality measurements of the seventh machine.\

### Separate model

Preparing the data
```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_separate <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_separate.stan")
model_separate <- cmdstan_model(file_separate)
model_separate$compile(quiet = FALSE)
result_separate <- model_separate$sample(data = stan_data, refresh=1000)
#result_separate$summary()
```
* i) the posterior distribution of the mean of the quality measurements of the sixth machine.\

```{r}
hist(result_separate$draws("mu[6]"), main="(Separate) Posterior distribution of the mean of\nthe quality measurements of the sixth machine", xlab="Quality measurement mean",breaks=30)
```


* ii) the predictive distribution for another quality measurement of the sixth machine.\
```{r}
hist(result_separate$draws("ypred[6]"), main="(Separate) Predictive distribution for another\nquality measurement of the sixth machine", xlab="Predicted quality measurement", breaks=30)
```

* iii) the posterior distribution of the mean of the quality measurements of the seventh machine.

In the separate model, the machines are independent of each other. Knowing the posterior distribution of the quality measurements of the six machines do not give any knowledge about the seventh machine. Therefore, it is infeasible to plot the posterior distribution of the
mean of the quality measurements of the seventh machine in the separate model.\

### Pooled model
Preparing the data
```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_pooled <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_pooled.stan")
model_pooled <- cmdstan_model(file_pooled)
model_pooled$compile(quiet = FALSE)
result_pooled <- model_pooled$sample(data = stan_data, refresh=1000)
#result_pooled$summary()
```

* i) the posterior distribution of the mean of the quality measurements of the sixth machine.\
A note is that this histogram is shared among all machines\
```{r}
hist(result_pooled$draws("mu"), main="(Pooled) Posterior distribution of the mean of\nthe quality measurements of the sixth machine", xlab="Quality measurement mean",breaks=30)
```
* ii) the predictive distribution for another quality measurement of the sixth machine.

A note is that this histogram is shared among all machines\
```{r}
hist(result_pooled$draws("ypred"), main="(Pooled) Predictive distribution for another\nquality measurement of the sixth machine", xlab="Predicted quality measurement", breaks=30)
```
* iii) the posterior distribution of the mean of the quality measurements of the seventh machine.

In the pooled model, all of the quality measurements come from the same distribution, which means there is no difference between the machines. As a result, the posterior distribution of the mean of the quality measurements of the seventh machine is similar to that of other machines, which is already plotted in part (i).\

### Hierarchical model
Preparing the data
```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_hierarchical <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_hierarchical.stan")
model_hierarchical <- cmdstan_model(file_hierarchical)
model_hierarchical$compile(quiet = FALSE)
result_hierarchical <- model_hierarchical$sample(data = stan_data, refresh=1000)
#result_hierarchical$summary()
```

* i) the posterior distribution of the mean of the quality measurements of the sixth machine.\
```{r}
hist(result_hierarchical$draws("mu"), main="(Hierarchical) Posterior distribution of the mean of\nthe quality measurements of the sixth machine", xlab="Quality measurement mean",breaks=35)
```


* ii) the predictive distribution for another quality measurement of the sixth machine.\
```{r}
hist(result_hierarchical$draws("ypred[6]"), main="(Hierarchical) Predictive distribution for another\nquality measurement of the sixth machine", xlab="Predicted quality measurement", breaks=35)
```

* iii) the posterior distribution of the mean of the quality measurements of the seventh machine.\

```{r}
hist(result_hierarchical$draws("ypred7"), main="(Hierarchical) Posterior distribution of the mean of\nthe quality measurements of the seventh machine", xlab="Quality measurement mean", breaks=30)
```

## d) 
Report the posterior expectation for $\mu_1$ with a 90% credible interval but using a normal(0; 10)
prior for the $\mu$ parameter(s) and a Gamma(1; 1) prior for the $\sigma$ parameter(s). For the
hierarchical model, use the normal(0; 10) and Gamma(1; 1) as hyper-priors.
Hint! See the example Stan codes here for the comparison of k groups with and without the
hierarchical structure.\

The function used to obtain the 90% quantile\
```{r}
ninetyPercentCredibleInterval <- function(dist, model) {
  meanDist <- mean(dist)
  lowerQuantile <- quantile(dist, 0.05)
  upperQuantile <- quantile(dist, 0.95)
  cat("The 90% credible interval of the posterior distribution for mu1 in the",model,"model")
  cat("\nThe mean:", meanDist)
  cat("\nThe 5% lower quantile:", lowerQuantile)
  cat("\nThe 95% upper quantil:", upperQuantile)
}
```

### Separate model

```{r, eval = FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  vector[K] mu;
  vector<lower=0>[K] sigma;
}

model {
  for (k in 1:K) {
    mu[k] ~ normal(0, 10);
    sigma[k] ~ gamma(1, 1);
  }
  for (k in 1:K) {
    y[, k] ~ normal(mu[k], sigma[k]);
  }
}

generated quantities {
  array[K] real ypred;
  for (k in 1:K) {
    ypred[k] = normal_rng(mu[k], sigma[k]);
  }
}

"
```

```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_separate_partd <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_separate_partd.stan")
model_separate_partd <- cmdstan_model(file_separate_partd)
model_separate_partd$compile(quiet = FALSE)
result_separate_partd <- model_separate_partd$sample(data = stan_data, show_messages=FALSE)
```

```{r}
ninetyPercentCredibleInterval(result_separate_partd$draws("mu[1]"),"separate")
```
### Pooled model

```{r, eval=FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  real mu; // There is only a single mu for all machines
  real<lower=0> sigma; // There is only a single sigma for all machines
}

model {
  // priors
  mu ~ normal(0, 10);
  sigma ~ gamma(1, 1);

  // likelihood
  for (k in 1:K){
    y[,k] ~ normal(mu, sigma);
  }
}

generated quantities {
  real ypred = normal_rng(mu, sigma);
}

"
```

```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_pooled_partd <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_pooled_partd.stan")
model_pooled_partd <- cmdstan_model(file_pooled_partd)
model_pooled_partd$compile(quiet = FALSE)
result_pooled_partd <- model_pooled_partd$sample(data = stan_data, show_messages=FALSE)
```

```{r}
ninetyPercentCredibleInterval(result_pooled_partd$draws("mu"), "pooled")
```

### Hierarchical model

```{r, eval=FALSE}
"
data {
  int<lower=0> N; // number of measurements per machine
  int<lower=0> K; // number of machines
  array[N] vector[K] y; // An array of vectors containing the table data
}

parameters {
  vector[K] mu;
  real sigma;
  real mu_tau;
  real sigma_tau;
  real mu_ypred7;
}

model {
  mu_tau ~ normal(0, 10);
  sigma_tau ~ gamma(1, 1);
  sigma ~ gamma(1, 1);
  mu_ypred7 ~ normal(mu_tau, sigma_tau);
  for (k in 1:K) {
    mu[k] ~ normal(mu_tau, sigma_tau);
  }
  for (k in 1:K) {
    y[, k] ~ normal(mu[k], sigma);
  }
}

generated quantities {
  array[K] real ypred;
  for (k in 1:K) {
    ypred[k] = normal_rng(mu[k] , sigma);
  }
  real ypred7 = normal_rng(mu_ypred7, sigma);
}

"
```

```{r}
stan_data <- list(
  y = factory,
  N = nrow(factory),
  K = ncol(factory)
)
file_hierarchical_partd <- file.path("C:/Users/nguye/Desktop/BDA/assignments/assignment 7", "ex2_model_hierarchical_partd.stan")
model_hierarchical_partd <- cmdstan_model(file_hierarchical_partd)
model_hierarchical_partd$compile(quiet = FALSE)
result_hierarchical_partd <- model_hierarchical_partd$sample(data = stan_data, show_messages=FALSE)

```

```{r}
ninetyPercentCredibleInterval(result_hierarchical_partd$draws("mu[1]"), "hierarchical")
```

